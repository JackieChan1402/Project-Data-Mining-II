import cv2
import numpy as np
import os
import matplotlib.pyplot as plt
from skimage.feature import hog
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

# ğŸ“Œ ThÆ° má»¥c chá»©a dá»¯ liá»‡u
image_folders = ["PART_1/images", "PART_2/PART_2/images", "PART_3/PART_3/images"]
annotation_folder = "PART_1/6categories"

# ğŸ“Œ Cáº¥u hÃ¬nh HOG
hog_params = {'orientations': 9, 'pixels_per_cell': (8, 8), 'cells_per_block': (2, 2)}

# ğŸ“Œ Cáº¥u hÃ¬nh bounding box
max_bbox = 40
num_bbox_features = max_bbox * 4

X, image_paths = [], []  # LÆ°u Ä‘Æ°á»ng dáº«n áº£nh Ä‘á»ƒ hiá»ƒn thá»‹

# ğŸ“Œ Duyá»‡t qua áº£nh trong cÃ¡c thÆ° má»¥c
for folder in image_folders:
    for image_name in os.listdir(folder):
        if image_name.endswith((".jpg", ".png")):
            image_path = os.path.join(folder, image_name)
            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

            if image is None:
                print(f"âš ï¸ Lá»—i Ä‘á»c áº£nh: {image_path}")
                continue

            image_resized = cv2.resize(image, (64, 64))

            # ğŸ“Œ TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng HOG
            hog_features = hog(image_resized, **hog_params)
            hog_features = hog_features.flatten()

            # ğŸ“Œ Äá»c annotation YOLO
            annotation_path = os.path.join(annotation_folder, image_name.replace(".jpg", ".txt").replace(".png", ".txt"))
            bbox_data = []

            if os.path.exists(annotation_path):
                with open(annotation_path, 'r') as f:
                    lines = f.readlines()
                    for line in lines[:max_bbox]:  # Chá»‰ láº¥y tá»‘i Ä‘a max_bbox bbox
                        values = line.strip().split()
                        bbox = list(map(float, values[1:]))  # Láº¥y x_center, y_center, width, height
                        bbox_data.extend(bbox)

            # ğŸ“Œ Padding náº¿u bbox < max_bbox
            if len(bbox_data) < num_bbox_features:
                bbox_data.extend([0.0] * (num_bbox_features - len(bbox_data)))

            bbox_data = np.array(bbox_data, dtype=np.float32)[:num_bbox_features]

            # ğŸ“Œ Káº¿t há»£p feature áº£nh + bbox
            feature_vector = np.hstack((hog_features, bbox_data))

            X.append(feature_vector)
            image_paths.append(image_path)

# ğŸ“Œ Chuyá»ƒn thÃ nh numpy array
X = np.array(X, dtype=np.float32)

# ğŸ“Œ Chuáº©n hÃ³a dá»¯ liá»‡u
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# ğŸ“Œ Giáº£m chiá»u báº±ng PCA
pca = PCA(n_components=50)
X_pca = pca.fit_transform(X_scaled)

# ğŸ“Œ Ãp dá»¥ng KMeans Clustering
num_clusters = 5  # Sá»‘ cá»¥m
kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init=10)
clusters = kmeans.fit_predict(X_pca)

# ğŸ“Œ Hiá»ƒn thá»‹ sá»‘ lÆ°á»£ng áº£nh trong má»—i cá»¥m
unique, counts = np.unique(clusters, return_counts=True)
cluster_info = dict(zip(unique, counts))
print("ğŸ“Œ Sá»‘ lÆ°á»£ng áº£nh trong má»—i cá»¥m:", cluster_info)

# ğŸ“Œ Váº½ biá»ƒu Ä‘á»“ phÃ¢n bá»‘ cá»¥m
plt.figure(figsize=(8, 5))
plt.bar(cluster_info.keys(), cluster_info.values(), color='blue', alpha=0.7)
plt.xlabel("Cluster ID")
plt.ylabel("Sá»‘ lÆ°á»£ng áº£nh")
plt.title("PhÃ¢n phá»‘i sá»‘ lÆ°á»£ng áº£nh trong cÃ¡c cá»¥m")
plt.xticks(range(num_clusters))
plt.show()

# ğŸ“Œ Hiá»ƒn thá»‹ má»™t sá»‘ áº£nh tá»« má»—i cá»¥m
fig, axes = plt.subplots(num_clusters, 5, figsize=(12, num_clusters * 3))

for cluster_id in range(num_clusters):
    cluster_indices = np.where(clusters == cluster_id)[0][:5]  # Chá»n 5 áº£nh tá»« cá»¥m nÃ y
    for i, idx in enumerate(cluster_indices):
        image = cv2.imread(image_paths[idx], cv2.IMREAD_GRAYSCALE)
        if image is None:
            continue  # Bá» qua áº£nh náº¿u bá»‹ lá»—i

        axes[cluster_id, i].imshow(image, cmap='gray')
        axes[cluster_id, i].axis("off")
        axes[cluster_id, i].set_title(f"Cluster {cluster_id}")

plt.tight_layout()
plt.show()
